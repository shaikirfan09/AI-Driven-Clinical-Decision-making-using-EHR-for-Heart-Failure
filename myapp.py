# -*- coding: utf-8 -*-
"""Myapp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zvCYRH-7HJA8aIT-CMx-yfBqYzbOuH-u
"""

app_code = """
import streamlit as st
import pandas as pd
import joblib
import lime
import lime.lime_tabular
import numpy as np
import streamlit.components.v1 as components

# --- 1. EXPERT SYSTEM LOGIC ---
def get_expert_advice(df):
    advices = []
    if df['Systolic_BP'].iloc[0] > 140:
        advices.append({"Factor": "High Blood Pressure", "Diet": "DASH diet; sodium <1,500mg/day.", "Exercise": "30-min brisk walk."})
    if df['Urea_Nitrogen_avg'].iloc[0] > 25:
        advices.append({"Factor": "Elevated Urea Nitrogen", "Diet": "Monitor protein; stay hydrated.", "Exercise": "Light activity."})
    if df['Potassium_avg'].iloc[0] > 5.0:
        advices.append({"Factor": "High Potassium", "Diet": "Avoid bananas/potatoes/spinach.", "Exercise": "Flexibility/Stretching."})
    if df['BMI'].iloc[0] > 30:
        advices.append({"Factor": "Elevated BMI", "Diet": "Caloric deficit; high fiber.", "Exercise": "Low-impact (Swimming)."})
    return advices

def main():
    try:
        model = joblib.load('mimic_model.joblib')
        feature_names = joblib.load('mimic_feature_names.joblib')
    except Exception as e:
        st.error(f"Error loading model: {e}")
        return

    explainer = lime.lime_tabular.LimeTabularExplainer(
        training_data=np.zeros((1, len(feature_names))),
        feature_names=feature_names,
        class_names=['Survived', 'Expired'],
        mode='classification'
    )

    st.set_page_config(page_title="Mortality Prediction", layout="wide")
    st.title('ðŸ©º AI Clinical Support: For Heart Failure Patients')

    # --- 2. SIDEBAR: PERFORMANCE COMPARISON ---
    st.sidebar.header('ðŸ“Š Model Benchmarking')
    show_metrics = st.sidebar.checkbox("Show Model Metrics", value=True)

    if show_metrics:
        # Hardcoded benchmarks based on MIMIC-III training results
        metrics_data = {
            "Metric": ["Accuracy", "Precision", "Recall (Sens.)", "F1-Score"],
            "Logistic Regression": ["79.2%", "76.5%", "81.0%", "78.7%"],
            "Random Forest": ["85.4%", "82.1%", "88.2%", "85.0%"]
        }
        metrics_df = pd.DataFrame(metrics_data)
        st.sidebar.table(metrics_df)
        st.sidebar.info("**Note:** Random Forest was selected as the final model due to superior **Recall**, which is critical for patient safety.")

    # --- 3. PATIENT INPUT ---
    st.sidebar.header('ðŸ‘¤ Patient Input Features')
    def user_input_features():
        age = st.sidebar.slider('Age', 20, 100, 65)
        gender = st.sidebar.selectbox('Gender', ('M', 'F'))
        bicarbonate_avg = st.sidebar.slider('Bicarbonate_avg', 15.0, 40.0, 25.0, 0.1)
        creatinine_avg  = st.sidebar.slider('Creatinine_avg', 0.4, 10.0, 1.2, 0.1)
        potassium_avg   = st.sidebar.slider('Potassium_avg', 2.5, 7.0, 4.0, 0.1)
        sodium_avg      = st.sidebar.slider('Sodium_avg', 120.0, 155.0, 138.0, 0.1)
        bun_avg         = st.sidebar.slider('Urea_Nitrogen_avg', 5.0, 100.0, 20.0, 0.1)
        systolic_bp  = st.sidebar.slider('Systolic_BP', 80.0, 220.0, 120.0, 0.1)
        diastolic_bp = st.sidebar.slider('Diastolic_BP', 40.0, 130.0, 80.0, 0.1)
        bmi          = st.sidebar.slider('BMI', 15.0, 50.0, 25.0, 0.1)

        has_diabetes = st.sidebar.selectbox('Diabetes?', ['No', 'Yes'])
        has_ckd = st.sidebar.selectbox('CKD?', ['No', 'Yes'])
        has_hypertension = st.sidebar.selectbox('Hypertension?', ['No', 'Yes'])

        data = {
            'age': age, 'gender': 0 if gender == 'M' else 1,
            'Bicarbonate_avg': bicarbonate_avg, 'Creatinine_avg': creatinine_avg,
            'Potassium_avg': potassium_avg, 'Sodium_avg': sodium_avg,
            'Urea_Nitrogen_avg': bun_avg, 'Systolic_BP': systolic_bp,
            'Diastolic_BP': diastolic_bp, 'BMI': bmi,
            'has_diabetes': 1 if has_diabetes == 'Yes' else 0,
            'has_ckd': 1 if has_ckd == 'Yes' else 0,
            'has_hypertension': 1 if has_hypertension == 'Yes' else 0
        }
        return pd.DataFrame(data, index=[0])[feature_names]

    input_df = user_input_features()

    # --- 4. MAIN DISPLAY AREA ---
    col_a, col_b = st.columns([1, 1])

    with col_a:
        st.subheader('Patient Input Summary')
        st.write(input_df)

    if st.button('Run Mortality Risk Prediction'):
        prob = model.predict_proba(input_df)[0][1]

        with col_b:
            st.subheader('Prediction Result')
            st.metric("Mortality Risk Score", f"{prob*100:.1f}%")
            if prob > 0.30:
                st.error('HIGH RISK DETECTED')
            else:
                st.success('LOW RISK DETECTED')

        st.markdown("---")

        # TABS for detailed analysis
        tab1, tab2, tab3 = st.tabs(["Explainable AI (LIME)", "Clinical Intervention Plan", "Model Comparison Summary"])

        with tab1:
            st.subheader('Why is the risk score this high/low?')
            exp = explainer.explain_instance(input_df.iloc[0].values, model.predict_proba, num_features=8, labels=(1,))
            components.html(exp.as_html(), height=400)

        with tab2:
            st.subheader("Targeted Lifestyle Recommendations")
            recs = get_expert_advice(input_df)
            if recs:
                for r in recs:
                    with st.expander(f"Recommendation for {r['Factor']}"):
                        st.write(f"**Dietary Strategy:** {r['Diet']}")
                        st.write(f"**Exercise Strategy:** {r['Exercise']}")
            else:
                st.success("Patient vitals are currently within stable management ranges.")

        with tab3:
            st.subheader("Final Model Choice: Random Forest")
            st.write("Below is the comparison of our final model against the baseline Logistic Regression model.")
            # Use a bar chart to show the performance gap
            comparison_chart = pd.DataFrame({
                "Model": ["Logistic Regression", "Random Forest"] * 3,
                "Value": [79.2, 85.4, 81.0, 88.2, 76.5, 82.1],
                "Metric": ["Accuracy", "Accuracy", "Recall", "Recall", "Precision", "Precision"]
            })
            st.bar_chart(comparison_chart, x="Metric", y="Value", color="Model", stack=False)
            st.write("**Analysis:** Random Forest shows a significant +7.2% improvement in Recall. This is the difference between catching a high-risk patient and missing them.")

if __name__ == '__main__':
    main()
"""

with open("app.py", "w") as f:
    f.write(app_code)
print("âœ… app.py updated with Metrics Comparison.")

!pip install -q lime
import lime
import lime.lime_tabular
print("âœ… LIME imported successfully.")

!pip install -q streamlit cloudflared lime joblib

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

!cp "/content/drive/MyDrive/CapstoneProject/mimic_model.joblib" .
!cp "/content/drive/MyDrive/CapstoneProject/mimic_feature_names.joblib" .

!pip install -q --ignore-installed blinker
!pip install -q streamlit

!pkill streamlit
!pkill cloudflared

# Download cloudflared binary
!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64

# Make it executable
!chmod +x cloudflared-linux-amd64

# Move to system path
!mv cloudflared-linux-amd64 /usr/local/bin/cloudflared

!cloudflared --version

!python -m streamlit --version

!python -m streamlit run app.py

!python -m streamlit run app.py &>/content/logs.txt &

!cloudflared tunnel --url http://localhost:8501