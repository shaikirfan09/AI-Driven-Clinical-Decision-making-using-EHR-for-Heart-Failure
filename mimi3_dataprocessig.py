# -*- coding: utf-8 -*-
"""MIMI3_Dataprocessig.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jVnIQ7pHoEZxpuG7-1iVMVTMO3FDh8WE
"""

# 1. Install Libraries (Colab)
# ============================================
!pip install -q scikit-learn pandas joblib lime


print("âœ… Libraries installed.")


# ============================================
# 2. Import Libraries
# ============================================
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
import joblib
import lime
import lime.lime_tabular
import numpy as np
from google.colab import drive
import os


# ============================================
# 3. Mount Drive and Load Data
# ============================================
drive.mount('/content/drive')


base_path = '/content/drive/MyDrive/CapstoneProject'


print("ðŸ“‚ Files in CapstoneProject folder:")
print(os.listdir(base_path))


# Core MIMIC tables
df_admissions    = pd.read_csv(os.path.join(base_path, 'ADMISSIONS.csv'),    low_memory=False)
df_patients      = pd.read_csv(os.path.join(base_path, 'PATIENTS.csv'),      low_memory=False)
df_diagnoses     = pd.read_csv(os.path.join(base_path, 'DIAGNOSES_ICD.csv'), low_memory=False)
df_labitems      = pd.read_csv(os.path.join(base_path, 'D_LABITEMS.csv'),    low_memory=False)
df_labevents     = pd.read_csv(os.path.join(base_path, 'LABEVENTS.csv'),     low_memory=False)
df_items         = pd.read_csv(os.path.join(base_path, 'D_ITEMS.csv'),       low_memory=False)
df_chartevents   = pd.read_csv(os.path.join(base_path, 'CHARTEVENTS.csv'),   low_memory=False)
df_prescriptions = pd.read_csv(os.path.join(base_path, 'PRESCRIPTIONS.csv'), low_memory=False)


# Patient problems table (used only to build flags, no num_problems)
problems_path = os.path.join(base_path, 'Patient Problems.csv')
df_problems = pd.read_csv(problems_path, low_memory=False)


print("âœ… All data tables loaded successfully!")


# ============================================
# 4. Heart Failure Cohort & Age
# ============================================
hf_icd_codes = df_diagnoses[df_diagnoses['icd9_code'].str.startswith('428', na=False)]
hf_admissions_ids = hf_icd_codes['hadm_id'].unique()


df_hf_admissions = df_admissions[df_admissions['hadm_id'].isin(hf_admissions_ids)]


df_merged = pd.merge(df_hf_admissions, df_patients, on='subject_id', how='inner')


df_merged['admittime'] = pd.to_datetime(df_merged['admittime'])
df_merged['dob']       = pd.to_datetime(df_merged['dob'])


def calculate_age(row):
    try:
        return (row['admittime'].to_pydatetime() - row['dob'].to_pydatetime()).days / 365.25
    except Exception:
        return np.nan


df_merged['age'] = df_merged.apply(calculate_age, axis=1)
df_merged.loc[df_merged['age'] > 89, 'age'] = 90


df_base = df_merged[['subject_id', 'hadm_id', 'age', 'gender', 'hospital_expire_flag']].drop_duplicates()
print("âœ… Base table created.")


# ============================================
# 5. Lab Features
# ============================================
key_lab_labels = ['Creatinine', 'Potassium', 'Sodium', 'Urea Nitrogen', 'Bicarbonate']
key_lab_ids = df_labitems[df_labitems['label'].isin(key_lab_labels)]['itemid']


df_key_labs = df_labevents[df_labevents['itemid'].isin(key_lab_ids)]


df_labs_avg = (
    df_key_labs
    .groupby(['hadm_id', 'itemid'])['valuenum']
    .mean()
    .reset_index()
)


df_labs_avg = pd.merge(
    df_labs_avg,
    df_labitems[['itemid', 'label']],
    on='itemid',
    how='inner'
)


df_labs_pivot = df_labs_avg.pivot_table(
    index='hadm_id',
    columns='label',
    values='valuenum',
    aggfunc='mean'
)


df_labs_pivot.columns = [col.replace(' ', '_') + '_avg' for col in df_labs_pivot.columns]


df_final = pd.merge(df_base, df_labs_pivot, on='hadm_id', how='left')
print("âœ… Lab features added.")


# ============================================
# 6. Vitals & BMI
# ============================================
bp_systolic_id  = 51
bp_diastolic_id = 8368
weight_id       = 763
height_id       = 920


key_chart_ids = [bp_systolic_id, bp_diastolic_id, weight_id, height_id]
df_key_charts = df_chartevents[df_chartevents['itemid'].isin(key_chart_ids)]


df_charts_avg = (
    df_key_charts
    .groupby(['hadm_id', 'itemid'])['valuenum']
    .mean()
    .reset_index()
)


df_charts_avg['label'] = df_charts_avg['itemid'].map({
    bp_systolic_id:  'Systolic_BP',
    bp_diastolic_id: 'Diastolic_BP',
    weight_id:       'Weight_kg',
    height_id:       'Height_cm'
})


df_charts_pivot = df_charts_avg.pivot_table(
    index='hadm_id',
    columns='label',
    values='valuenum',
    aggfunc='mean'
)


df_final = pd.merge(df_final, df_charts_pivot, on='hadm_id', how='left')


df_final['BMI'] = df_final['Weight_kg'] / ((df_final['Height_cm'] / 100.0) ** 2)
print("âœ… Vitals and BMI added.")


# ============================================
# 7. Patient Problems â†’ flags only (no num_problems, no COPD)
# ============================================
problem_col = 'diagnosis'   # adjust if needed
hadm_col    = 'patient_id'  # in this CSV, patient identifier


if problem_col not in df_problems.columns or hadm_col not in df_problems.columns:
    print("Columns in Patient Problems.csv:", df_problems.columns)
    raise KeyError("Adjust problem_col/hadm_col to match Patient Problems.csv")


df_problems = df_problems.dropna(subset=[hadm_col])
df_problems[problem_col] = df_problems[problem_col].astype(str).str.lower()


def has_keyword(series, keywords):
    text = ' '.join(series.dropna().tolist())
    return int(any(kw in text for kw in keywords))


problem_flags = []
for pid, group in df_problems.groupby(hadm_col):
    probs = group[problem_col]
    flags = {
        hadm_col: pid,
        'has_diabetes':     has_keyword(probs, ['diabetes', 'dm']),
        'has_ckd':          has_keyword(probs, ['ckd', 'chronic kidney', 'renal failure']),
        'has_hypertension': has_keyword(probs, ['hypertension', 'htn'])
    }
    problem_flags.append(flags)


df_prob_features = pd.DataFrame(problem_flags).rename(columns={'patient_id': 'subject_id'})


df_final = pd.merge(df_final, df_prob_features, on='subject_id', how='left')


for col in ['has_diabetes', 'has_ckd', 'has_hypertension']:
    if col in df_final.columns:
        df_final[col] = df_final[col].fillna(0)





# ============================================
# 8. Final Cleanup & Model Training
# ============================================
from sklearn.model_selection import train_test_split  # you can keep or remove this import if unused

features = [
    'age',
    'gender',
    'Bicarbonate_avg',
    'Creatinine_avg',
    'Potassium_avg',
    'Sodium_avg',
    'Urea_Nitrogen_avg',
    'Systolic_BP',
    'Diastolic_BP',
    'BMI',
    'has_diabetes',
    'has_ckd',
    'has_hypertension'
]

core_features = [
    'age',
    'gender',
    'Bicarbonate_avg',
    'Creatinine_avg',
    'Potassium_avg',
    'Sodium_avg',
    'Urea_Nitrogen_avg',
    'Systolic_BP',
    'Diastolic_BP',
    'BMI'
]

df_final = df_final.dropna(subset=core_features)

X = df_final[features].copy()
y = df_final['hospital_expire_flag']

# encode gender
X['gender'] = X['gender'].apply(lambda s: 1 if s == 'F' else 0)

# train model on all data (no accuracy printed)
model = RandomForestClassifier(
    n_estimators=100,
    random_state=42,
    class_weight='balanced'
)
model.fit(X, y)

# ============================================
# 9. Save Model and Feature Names
# ============================================
joblib.dump(model,           os.path.join(base_path, 'mimic_model.joblib'))
joblib.dump(X.columns.tolist(), os.path.join(base_path, 'mimic_feature_names.joblib'))